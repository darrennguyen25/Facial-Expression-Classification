{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7092794,"sourceType":"datasetVersion","datasetId":4087510}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom torchvision import transforms\n\n# Check for GPU availability\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Load and preprocess data\ntrain_data = pd.read_csv(\"/kaggle/input/facialrecog/train_data.csv\", header=None)\ntrain_targets = pd.read_csv(\"/kaggle/input/facialrecog/train_target.csv\", header=None)\ntest_data = pd.read_csv(\"/kaggle/input/facialrecog/test_data.csv\", header=None)\n\n# Convert to PyTorch tensors\nX_train = torch.Tensor(train_data.values.reshape(-1, 1, 48, 48)).to(device)  # Assuming images are grayscale\ny_train = torch.LongTensor(train_targets.values.flatten()).to(device)\n\nX_test = torch.Tensor(test_data.values.reshape(-1, 1, 48, 48)).to(device)\n\n# Normalize pixel values to the range [0, 1]\nX_train /= 255.0\nX_test /= 255.0\n\n# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\n# Data Augmentation\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ToTensor()\n])\n\naugmented_dataset = TensorDataset(X_train, y_train)\n\n# Define a Neural Network\nclass FacialExpressionModel(nn.Module):\n    def __init__(self):\n        super(FacialExpressionModel, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n        self.batch_norm1 = nn.BatchNorm2d(32)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.batch_norm2 = nn.BatchNorm2d(64)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.batch_norm3 = nn.BatchNorm2d(128)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(128 * 6 * 6, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, 3)  # 3 classes: Angry, Happy, Neutral\n        self.dropout = nn.Dropout(0.3)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.batch_norm1(self.conv1(x))))\n        x = self.pool(F.relu(self.batch_norm2(self.conv2(x))))\n        x = self.pool(F.relu(self.batch_norm3(self.conv3(x))))\n        x = x.view(-1, 128 * 6 * 6)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = self.fc3(x)\n        return x\n\n# Loss Function and Optimizer\nmodel = FacialExpressionModel().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Learning Rate Scheduler\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n\n# Training Loop\nnum_epochs = 15\nbatch_size = 64\n\ntrain_loader = DataLoader(dataset=augmented_dataset, batch_size=batch_size, shuffle=True)\n\nfor epoch in range(num_epochs):\n    model.train()\n    for i, (images, labels) in enumerate(train_loader):\n        # Move data to GPU\n        images, labels = images.to(device), labels.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if (i+1) % 100 == 0:\n            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n\n    # Learning rate schedule step\n    scheduler.step()\n\n# Validation\nmodel.eval()\nwith torch.no_grad():\n    val_outputs = model(X_val)\n    val_loss = criterion(val_outputs, y_val)\n    _, val_preds = torch.max(val_outputs, 1)\n\n    accuracy = (val_preds == y_val).sum().item() / len(y_val)\n    print(f'Validation Accuracy: {accuracy:.4f}')\n\n# Test the Model\nmodel.eval()\nwith torch.no_grad():\n    test_outputs = model(X_test)\n    _, test_preds = torch.max(test_outputs, 1)\n\n# Save Predictions to CSV\nsubmission_df = pd.DataFrame({'Id': range(len(test_preds)), 'Category': test_preds.cpu().numpy()})\nsubmission_df.to_csv('/kaggle/working/predictions.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:03:37.643836Z","iopub.execute_input":"2023-12-01T09:03:37.644145Z","iopub.status.idle":"2023-12-01T09:07:49.463542Z","shell.execute_reply.started":"2023-12-01T09:03:37.644123Z","shell.execute_reply":"2023-12-01T09:07:49.462426Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Using device: cpu\nEpoch [1/10], Step [100/203], Loss: 1.0179\nEpoch [1/10], Step [200/203], Loss: 0.8406\nEpoch [2/10], Step [100/203], Loss: 0.8278\nEpoch [2/10], Step [200/203], Loss: 0.6997\nEpoch [3/10], Step [100/203], Loss: 0.6961\nEpoch [3/10], Step [200/203], Loss: 0.6798\nEpoch [4/10], Step [100/203], Loss: 0.4683\nEpoch [4/10], Step [200/203], Loss: 0.4783\nEpoch [5/10], Step [100/203], Loss: 0.5607\nEpoch [5/10], Step [200/203], Loss: 0.6677\nEpoch [6/10], Step [100/203], Loss: 0.5872\nEpoch [6/10], Step [200/203], Loss: 0.6245\nEpoch [7/10], Step [100/203], Loss: 0.4538\nEpoch [7/10], Step [200/203], Loss: 0.4978\nEpoch [8/10], Step [100/203], Loss: 0.4469\nEpoch [8/10], Step [200/203], Loss: 0.3739\nEpoch [9/10], Step [100/203], Loss: 0.2991\nEpoch [9/10], Step [200/203], Loss: 0.4666\nEpoch [10/10], Step [100/203], Loss: 0.3619\nEpoch [10/10], Step [200/203], Loss: 0.4448\nValidation Accuracy: 0.7651\n","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-30T17:18:33.521251Z","iopub.execute_input":"2023-11-30T17:18:33.521601Z","iopub.status.idle":"2023-11-30T17:18:33.955559Z","shell.execute_reply.started":"2023-11-30T17:18:33.521571Z","shell.execute_reply":"2023-11-30T17:18:33.954753Z"},"trusted":true},"execution_count":null,"outputs":[]}]}